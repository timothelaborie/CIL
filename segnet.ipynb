{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.seg_net_lite import SegNetLite\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 400, 400])\n",
      "torch.Size([4, 3, 400, 400])\n",
      "torch.Size([4, 1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "# Set up the DataLoader for the dataset\n",
    "class SegNetDataset(Dataset):\n",
    "    def __init__(self, image_folder, groundtruth_folder, image_transform=None, groundtruth_transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.groundtruth_folder = groundtruth_folder\n",
    "        self.image_transform = image_transform\n",
    "        self.groundtruth_transform = groundtruth_transform\n",
    "        self.image_files = os.listdir(image_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_folder, self.image_files[idx])\n",
    "        groundtruth_path = os.path.join(self.groundtruth_folder, self.image_files[idx])\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        groundtruth = Image.open(groundtruth_path).convert(\"L\")\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.groundtruth_transform:\n",
    "            groundtruth = self.groundtruth_transform(groundtruth)\n",
    "\n",
    "        return image, groundtruth\n",
    "\n",
    "\n",
    "# Initialize the DataLoader\n",
    "image_transform = Compose([ToTensor()])\n",
    "groundtruth_transform = Compose([ToTensor()])\n",
    "\n",
    "train_data = SegNetDataset(\"training/images\", \"training/groundtruth\", image_transform=image_transform, groundtruth_transform=groundtruth_transform)\n",
    "\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SegNetLite().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "# Initialize weights\n",
    "print(model(torch.randn(4, 3, 400, 400).to(device)).shape)\n",
    "print(iter(train_loader).next()[0].shape)\n",
    "print(iter(train_loader).next()[1].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimothelaborie\u001b[0m (\u001b[33mtlaborie\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Timothe\\Documents\\eth4\\cil\\github\\CIL\\wandb\\run-20230422_115751-b3vuewkn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tlaborie/CIL%202023/runs/b3vuewkn' target=\"_blank\">unique-galaxy-1</a></strong> to <a href='https://wandb.ai/tlaborie/CIL%202023' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tlaborie/CIL%202023' target=\"_blank\">https://wandb.ai/tlaborie/CIL%202023</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tlaborie/CIL%202023/runs/b3vuewkn' target=\"_blank\">https://wandb.ai/tlaborie/CIL%202023/runs/b3vuewkn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 0.8241235387736353\n",
      "Epoch 1/5, Validation F1 Score: 0.08127966611021101\n",
      "Epoch 2/5, Training Loss: 0.694300495345017\n",
      "Epoch 2/5, Validation F1 Score: 0.7054073081128847\n",
      "Epoch 3/5, Training Loss: 0.6556050201942181\n",
      "Epoch 3/5, Validation F1 Score: 0.756407933885076\n",
      "Epoch 4/5, Training Loss: 0.6397893182162581\n",
      "Epoch 4/5, Validation F1 Score: 0.8142654235132142\n",
      "Epoch 5/5, Training Loss: 0.6302901177570738\n",
      "Epoch 5/5, Validation F1 Score: 0.7997513196757334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909f32b60a074919b74c8b672bca5d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▃▂▁▁</td></tr><tr><td>Validation F1 Score</td><td>▁▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>0.63029</td></tr><tr><td>Validation F1 Score</td><td>0.79975</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-galaxy-1</strong> at: <a href='https://wandb.ai/tlaborie/CIL%202023/runs/b3vuewkn' target=\"_blank\">https://wandb.ai/tlaborie/CIL%202023/runs/b3vuewkn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_115751-b3vuewkn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"CIL 2023\", entity=\"tlaborie\")\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "# Set up the training and validation loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    for batch_idx, (images, groundtruths) in enumerate(train_loader):\n",
    "        images, groundtruths = images.to(device), groundtruths.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, groundtruths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    wandb.log({\"Train Loss\": avg_train_loss})\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    total_f1 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, groundtruths in val_loader:\n",
    "            images, groundtruths = images.to(device), groundtruths.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.cpu().numpy()\n",
    "            preds[preds >= 0.5] = 1\n",
    "            preds[preds < 0.5] = 0\n",
    "            groundtruths = groundtruths.cpu().numpy()\n",
    "            total_f1 += f1_score(groundtruths.flatten(), preds.flatten(), average='weighted')\n",
    "\n",
    "    val_f1 = total_f1 / len(val_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation F1 Score: {val_f1}\")\n",
    "    wandb.log({\"Validation F1 Score\": val_f1})\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
